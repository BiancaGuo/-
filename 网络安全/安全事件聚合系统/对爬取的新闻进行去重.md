## 安全新闻聚合系统 之 对爬取的新闻数据进行去重

### 思路：借助simhash算法

* 定义

	simhash是google用来处理海量文本去重的算法。 它能将一段文字转换成一个64位的字节，然后判断重复只需要判断他们的特征字的海明距离就可以判断两个文档是否相似。按照Charikar在论文中阐述的，64位simhash，海明距离在3以内的文本都可以认为是近重复文本。当然，具体数值需要结合具体业务以及经验值来确定。 

* 实现

	1、将文本进行分词并计算权重

	2、关键词提取

	3、计算Simhash值

	4、根据simhash的值计算两个文本之间的相似度

	5、对获取到的所有新闻数据进行相似度比较，找到相似度大于设定阈值的两篇文章，将其中一篇文章的news_url和title字段更新到数据库的另一篇文章的相应字段中，将本篇文章的这两个字段置为空

	6、最终只输出数据库中title或news_url不为空的字段，达到了去重的效果


* 代码关键点解释

	

* 测试效果

![](https://i.imgur.com/wrnZcJZ.jpg)

![](https://i.imgur.com/0ISF7N7.jpg)




	